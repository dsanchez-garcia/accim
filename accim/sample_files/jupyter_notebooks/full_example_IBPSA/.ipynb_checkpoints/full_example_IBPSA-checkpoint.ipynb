{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3991fa3e",
   "metadata": {},
   "source": [
    "# Full example of adaptive setpoint temperature simulation: IBPSA webinar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e978db",
   "metadata": {},
   "source": [
    "In this section, we're going to run a simulation with adaptive setpoint temperatures. Say we want to run some simulations using a [Brazilian local comfort model](https://linkinghub.elsevier.com/retrieve/pii/S0378778817331079) developed by Ricardo Forgiarini Rupp et al [1] in some locations in Brazil, and also we want to **analyse and visualize the data**. First of all, given EnergyPlus (any version between 9.1 and 23.1 included) is installed, and accim has been installed by entering 'pip install accim' in the CMD terminal, let's prepare the files we need: the IDF(s) and the EPW(s). Let's see what file we have in the folder and then we'll continue with the IDF(s).\n",
    "\n",
    "[1] R.F. Rupp, R. de Dear, E. Ghisi, Field study of mixed-mode office buildings in Southern Brazil using an adaptive thermal comfort framework, Energy and Buildings. 158 (2018) 1475–1486. https://doi.org/10.1016/j.enbuild.2017.11.047."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd6f4d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "backup\n",
      "Current_GC07_Chapeco.epw\n",
      "Current_GC20_Palmas.epw\n",
      "full_example_IBPSA.ipynb\n",
      "RCP852100_GC07_Chapeco.epw\n",
      "RCP852100_GC20_Palmas.epw\n",
      "TestModel.idf\n",
      "__init__.py\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "input_files = [i for i in listdir()]\n",
    "print(*input_files, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60983e3c",
   "metadata": {},
   "source": [
    "The building energy model used is a simple 2-zone model done in DesignBuilder with all parameters by default. We only set the natural ventilation to calculated, and allowed natural ventilation in the HVAC tab for the 2 zones. If you want to have a look at the IDF, you can load it in [Ladybug's Spider IDF Viewer](https://www.ladybug.tools/spider-2020/spider-idf-viewer/v-2020-10-09/spider-idf-viewer.html).\n",
    "\n",
    "At this point, the methodology is composed of the following sections and subsections:\n",
    "- __1. Data pre-processing__\n",
    "    - __1.1. Implementing ACCIS__\n",
    "    - __1.2. Preparing EPW files__\n",
    "- __2. Running simulations__\n",
    "- __3. Data post-processing__\n",
    "    - __3.1 Visualizing the data__\n",
    "    - __3.2 Analysing the data__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca521d4",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b71ab",
   "metadata": {},
   "source": [
    "### 1.1. Implementing ACCIS (using `addAccis()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a5c34",
   "metadata": {},
   "source": [
    "Say we have one or multiple IDF files, with an existing HVAC system (in this case, the use of mixed-mode ScriptType 'ex_mm' is not recommended; only full air-conditioning) or with no HVAC system at all (in this case, any of the 'vrf_ac' or 'vrf_mm' ScriptTypes are recommended). In this example, we are going to use an IDF without HVAC system, and we are going to use 'vrf_mm' so that accim adds a generic VRF system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939dcd3",
   "metadata": {},
   "source": [
    "Let's see what IDFs we do have in our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_idfs = [i for i in listdir() if i.endswith('.idf')]\n",
    "print(input_idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ac1b0",
   "metadata": {},
   "source": [
    "So now, we're going to generate building energy models with setpoint temperatures based on the Japanese comfort model (i.e. ComfStand takes the value 3) and ASHRAE 55 (i.e. ComfStand takes the value 2). We're going to select the 80% acceptability levels for both (i.e. CAT takes the value 80), and we're going to select the setpoint behaviour to horizontally extend the setpoint temperatures (or comfort limits) when applicability limits are exceeded (i.e. ComfMod takes the value 3). There are 2 methods to apply adaptive setpoint temperatures:\n",
    "- Short method, which is running the following to lines of code:\n",
    "```\n",
    "from accim.sim import accis\n",
    "accis.addAccis()\n",
    "```\n",
    "\n",
    "When we run the 2 lines of code above, accim is going to ask us to enter some information it needs to generate the output IDFs. The data we're going to input, in the same order, is:\n",
    "- Enter the ScriptType: **vrf_mm**\n",
    "- Enter the SupplyAirTempInputMethod: **temperature difference**\n",
    "- Do you want to keep the existing outputs (true or false)?: **false**\n",
    "- Enter the Output type (standard, simplified or detailed): **standard**\n",
    "- Enter the Output frequencies separated by space (timestep, hourly, daily, monthly, runperiod): **monthly**\n",
    "- Enter the EnergyPlus version (9.1 to 23.1): **23.1**\n",
    "- Enter the Temperature Control method (temperature or pmv): **temperature**\n",
    "\n",
    "After that, accim will let us know the information we have entered, and it will start the generic IDF generation process. Lots of actions are going to be performed, and all of them will be printed on screen. Once this process is done, accim will let us know if any of the IDFs is not going to work for any reason, and then it will start the output IDF files generation process. Then, accim will ask us again to enter some information, this time to generate the output IDF(s). The data we are going to enter now is:\n",
    "\n",
    "- Enter the Comfort Standard numbers separated by space: **15**\n",
    "- Enter the Category numbers separated by space: **80**\n",
    "- Enter the Comfort Mode numbers separated by space: **0 3** (where 0 and 3 are respectively static and adaptive setpoints)\n",
    "- Enter the HVAC Mode numbers separated by space: **0 1 2** (in this case we have also selected 1 for naturally ventilated, to see the difference with mixed-mode)\n",
    "- Enter the Ventilation Control numbers separated by space: **0**\n",
    "\n",
    "For all the remaining arguments, we're going to hit enter to omit it and take the default value. Finally, accim will let us know the list of output IDFs and will ask for confirmation to proceed:\n",
    "\n",
    "- Do you still want to run ACCIS? [y/n]: **y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6581501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.sim import accis\n",
    "accis.addAccis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372843fa",
   "metadata": {},
   "source": [
    "Alternatively, we could specify all the arguments when calling the function, as shown in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.sim import accis\n",
    "add_accis_instance = accis.addAccis(\n",
    "    ScriptType='vrf_mm',\n",
    "    SupplyAirTempInputMethod='temperature difference',\n",
    "    Output_keep_existing=False,\n",
    "    Output_type='standard',\n",
    "    Output_freqs=['hourly', 'monthly'],\n",
    "    EnergyPlus_version='23.1',\n",
    "    TempCtrl='temperature',\n",
    "    ComfStand=[15],\n",
    "    CAT=[80],\n",
    "    ComfMod=[0, 3],\n",
    "    SetpointAcc=1000,\n",
    "    HVACmode=[1, 2],\n",
    "    VentCtrl=[0],\n",
    "    VSToffset=[0],\n",
    "    MinOToffset=[50],\n",
    "    MaxWindSpeed=[50],\n",
    "    ASTtol_steps=0.1,\n",
    "    ASTtol_start=0.1,\n",
    "    ASTtol_end_input=0.1,\n",
    "    confirmGen=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557fa1e",
   "metadata": {},
   "source": [
    "So, now let's see the list of output IDFs we have generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58217779",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_idfs = [i for i in listdir() if i.endswith('.idf') and i not in input_idfs]\n",
    "print(*output_idfs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a27ab",
   "metadata": {},
   "source": [
    "Now, let's have a look at the internal variables which have been stored in the ``addAccis`` instance we have done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d70647",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in dir(add_accis_instance) if '__' not in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0d90c",
   "metadata": {},
   "source": [
    "For instance, in arguments, you can see the arguments you have previously specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880528aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_accis_instance.arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62982c",
   "metadata": {},
   "source": [
    "In variables  ``occupied_zones``, ``occupied_zones_original_name``, ``windows_and_doors`` and\n",
    " ``windows_and_doors_original_name`` you can see the zones and windows and doors within the input idfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_accis_instance.occupied_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_accis_instance.windows_and_doors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02430489",
   "metadata": {},
   "source": [
    "In variables ``input_idfs`` and ``output_idfs`` you can inspect the input and output idfs using eppy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5194312",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_accis_instance.input_idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_accis_instance.input_idfs['TestModel'].idfobjects['Schedule:Compact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c04495",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_accis_instance.input_idfs['TestModel'].idfobjects['EnergyManagementSystem:Program']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb114b",
   "metadata": {},
   "source": [
    "Now, let's see the variable ``output_idfs`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa73881",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_accis_instance.output_idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf53944",
   "metadata": {},
   "source": [
    "And let's read the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70529c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = 'TestModel[CS_BRA Rupp NV[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf'\n",
    "add_accis_instance.output_idfs[first_model].idfobjects['EnergyManagementSystem:Program']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d3716",
   "metadata": {},
   "source": [
    "As you can see, in this case there are a couple of EMS Program objects, which compose ACCIS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2541a",
   "metadata": {},
   "source": [
    "In this case, we have generated more IDFs than we need, so let's remove the others. We only want a single naturally ventilated IDF, to compare the indoor temperature with the mixed-mode IDF with adaptive setpoints. IDFs are NV when HVACmode takes the value 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs_to_be_removed = [i for i in listdir() if i.endswith('.idf') and 'HM_1' in i and 'CS_BRA Rupp NV[CA_80[CM_3[HM_1' not in i]\n",
    "print(*idfs_to_be_removed, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69685a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "for i in idfs_to_be_removed:\n",
    "    remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346defc",
   "metadata": {},
   "source": [
    "Let's see what IDFs we do finally have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_idfs = [i for i in listdir() if i.endswith('.idf') and i not in input_idfs]\n",
    "print(*output_idfs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519dc414",
   "metadata": {},
   "source": [
    "So, we're done with the IDFs. You can see these have been named based on the input data, separated by the character '['. Let's move to the EPWs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92c008",
   "metadata": {},
   "source": [
    "### 1.2. Preparing EPW files (using `rename_epw_files()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4e6d8",
   "metadata": {},
   "source": [
    "Let's see the EPWs we are going to use for the simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624b8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_epws = [i for i in listdir() if i.endswith('.epw')]\n",
    "print(*original_epws, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8774f0",
   "metadata": {},
   "source": [
    "However, we don't want to run the simulations using that name. To ease the later data analysis, we are going to rename the EPW files following the pattern 'Country_City_RCPscenario-Year'. This way, data will be able to be grouped by country, city, RCP scenario and year. So let's rename them running the code in the cell below.\n",
    "\n",
    "First, accim will try to rename them based on the original name and the geolocation. If no match between those is found, accim will assign the string 'UNKNOWN' to the city. Then, accim will ask you if you want to edit some of the new names. If so, you'll need to enter the IDs:\n",
    "- If any of the city or subcountry names needs some amendment (if you are not happy with any of the available options, you can exclude it from renaming at the next stage), please enter the EPW IDs separated by space:**(hit enter)**\n",
    "\n",
    "Afterwards, you'll be asked to enter the new city name for each ID you previously entered (in this case, 0 1 2 3). So, \n",
    "- Regarding the file ID: 0 ... Please enter the amended city or subcountry, which must be unique: **Naha**\n",
    "- Regarding the file ID: 1 ... Please enter the amended city or subcountry, which must be unique: **Sapporo**\n",
    "- Regarding the file ID: 2 ... Please enter the amended city or subcountry, which must be unique: **Naha**\n",
    "- Regarding the file ID: 3 ... Please enter the amended city or subcountry, which must be unique: **Sapporo**\n",
    "\n",
    "Then, accim will let you know the old names, and the new named after amendments. Next, accim will ask you if you want to exclude some EPW from renaming. In this case, we're just going to hit enter to continue because we don't want to exclude any:\n",
    "- If you want to exclude some EPWs from renaming, please enter the new names separated by space, otherwise, hit enter to continue:\n",
    "\n",
    "Finally, accim will ask for confirmation to proceed with the renaming:\n",
    "Do you want to rename the file or files? [y/n]:**y**\n",
    "\n",
    "At this point, accim will make a copy of the EPWs and rename them. Afterwards, we would be asked if we want to delete the older EPWs. In this case, we won't because the deletion has been already set to False in the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.data.data_preprocessing import rename_epw_files\n",
    "rename_epw_files(\n",
    "    rename_dict={\n",
    "        'Chapeco': 'Chapeco',\n",
    "        'Palmas': 'Palmas'\n",
    "    },\n",
    "    confirm_deletion=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d86b25e",
   "metadata": {},
   "source": [
    "``rename_epw_files`` uses OpenStreetMap to extract the address from coordinates. If you get an SSL certificate error, you might need to find a different way to rename the files. You could also proceed without renaming them, but you could only make comparisons based on the entire EPW filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "for i in original_epws:\n",
    "    shutil.copy(i, i.split('.epw')[0]+'_new.epw')\n",
    "\n",
    "renaming_epws = {\n",
    "    'Current_GC07_Chapeco_new.epw': 'Brazil_Chapeco_Present.epw',\n",
    "    'Current_GC20_Palmas_new.epw': 'Brazil_Palmas_Present.epw',\n",
    "    'RCP852100_GC07_Chapeco_new.epw': 'Brazil_Chapeco_RCP85-2100.epw',\n",
    "    'RCP852100_GC20_Palmas_new.epw': 'Brazil_Palmas_RCP85-2100.epw',\n",
    "}\n",
    "\n",
    "for i in renaming_epws:\n",
    "    os.rename(i, renaming_epws[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f247dd9",
   "metadata": {},
   "source": [
    "Now, let's see what EPWs we do have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abc6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epws = [i for i in listdir() if i.endswith('.epw')]\n",
    "print(*all_epws, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a4f14",
   "metadata": {},
   "source": [
    "We can see the new EPWs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_epws = [i for i in listdir() if i.endswith('.epw') if i not in original_epws]\n",
    "print(*new_epws, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88b38e",
   "metadata": {},
   "source": [
    "EPWs are correctly renamed, so now let's move the old EPWs to a different folder to save them as a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for i in original_epws:\n",
    "    shutil.move(i, f'backup/{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc6f12",
   "metadata": {},
   "source": [
    "Now, we can move to the next stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe727e8",
   "metadata": {},
   "source": [
    "## 2. Running the simulation (using `runEp()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16603780",
   "metadata": {},
   "source": [
    "At this point, we have prepared the IDF(s) we are going to simulate, which are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c534e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*output_idfs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfc9e5b",
   "metadata": {},
   "source": [
    "as well as the locations where we are going to run those simulations, whose EPWs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*new_epws, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc9fcfb",
   "metadata": {},
   "source": [
    "So, we are going to simulate all IDF(s) with all EPW(s). When we run later the simulations using accim, the output files (i.e. the CSVs) will be named following the pattern **'idf[epw'**, where the character '[' is used as a separator for later data analysis, so that CSV rows can be grouped by EPW location. You may have noticed the same character is used as a separator in the IDF name, in order to group the CSV rows depending on the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac424a70",
   "metadata": {},
   "source": [
    "To run the simulations, 2 methods can be used:\n",
    "- the shorter, in which the following 2 lines of code needs to be run:\n",
    "    ```\n",
    "    from accim.run import run\n",
    "    run.runEp()\n",
    "    ```\n",
    "   After this, you'll be asked to enter the EnergyPlus version (which should coincide with the IDF EnergyPlus version):\n",
    "    - Please enter the desired EnergyPlus version: **23.1**\n",
    "    \n",
    "   Then, you will need to say if you want to run only output IDFs of accim, or otherwise all existing IDFs in the folder:\n",
    "    - Do you want to run only ACCIM output IDFs? [y or n]: **y**\n",
    "    \n",
    "   Next, accim will tell you the IDF(s) and EPW(s) it's going to use for the simulations, and finally all the simulations it's going to run based on the name pattern 'idf[epw'.\n",
    "   Finally, it will ask for confirmation to proceed with the simulation:\n",
    "    - Do you still want to proceed? [y or n]:**y**\n",
    "- the longer method, in which the parameters are specified when calling the function. We'll use the longer method, so let's run the cell below. Since there are a few simulations, it might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17de90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.run import run\n",
    "import time\n",
    "start=time.time()\n",
    "run.runEp(\n",
    "    runOnlyAccim=True, #only runs output IDFs, that is, IDFs with \"[\" in its name\n",
    "    confirmRun=True, #to skip confirmation\n",
    "    num_CPUs=4, #to specify the number of CPUs to be used\n",
    "    EnergyPlus_version='23.1', #to specify the EnergyPlus version of the IDF, and the version of EnergyPlus you are going to run\n",
    ")\n",
    "end=time.time()\n",
    "time_taken=end-start\n",
    "print(f'It has taken {time_taken} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89d15a",
   "metadata": {},
   "source": [
    "So simulations are done. Let's see the CSV data we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692742de",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = [i for i in listdir() if i.endswith('.csv') and 'Zsz.csv' not in i and 'Table.csv' not in i]\n",
    "print(*csvs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43224aa7",
   "metadata": {},
   "source": [
    "Now, we can move to the last stage, in which data will be analysed and visualized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b781bd",
   "metadata": {},
   "source": [
    "## 3. Data post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201e8b4",
   "metadata": {},
   "source": [
    "In order to analyse and visualize the data, we need to make a pandas DataFrame out of the CSVs. We will do this by using the `Table()` method. To use this method, a minimum knowledge and experience with Python programming is needed, so if this is not your case, you may struggle to make it work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292627c2",
   "metadata": {},
   "source": [
    "### 4.1 Visualizing the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82037ddf",
   "metadata": {},
   "source": [
    "Let's create an hourly dataframe, since firstly we are going to compare indoor temperature with and without adaptive setpoint temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.data.data_postprocessing import Table\n",
    "dataset_hourly = Table(\n",
    "    #datasets=list #Since we are not specifying any list, it will use all available CSVs in the folder\n",
    "    source_frequency='hourly', # This lets accim know which is the frequency of the input CSVs. Input CSVs with multiple frequencies are also allowed. It can be 'hourly', 'daily', 'monthly' and 'runperiod'. It can also be 'timestep' but might generate errors.\n",
    "    frequency='hourly', # If 'daily', accim will aggregate the rows in days. It can be 'hourly', 'daily', 'monthly' and 'runperiod'. It can also be 'timestep' but might generate errors.\n",
    "    frequency_agg_func='sum', #this makes the sum or average when aggregating in days, months or runperiod; since the original CSV frequency is in hour, it won't make any aeffect\n",
    "    standard_outputs=True, \n",
    "    level=['building'], # A list containing the strings 'block' and/or 'building'. For instance, if ['block', 'building'], accim will generate new columns to sum up or average in blocks and building level.\n",
    "    level_agg_func=['sum', 'mean'], # A list containing the strings 'sum' and/or 'mean'. For instance, if ['sum', 'mean'], accim will generate the new columns explained in the level argument by summing and averaging.\n",
    "    level_excluded_zones=[],\n",
    "    split_epw_names=True, #to split EPW names based on the pattern Country_City_RCPscenario-Year\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4581f539",
   "metadata": {},
   "source": [
    "Let's filter the columns we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.format_table(\n",
    "    type_of_table='custom', # Used to choose some predefined tables. It can be 'energy demand', 'comfort hours', 'temperature', 'all' or 'custom'\n",
    "    custom_cols=[ #if type_of_table is 'custom', custom_cols is used to filter the desired columns to keep\n",
    "        'Adaptive Cooling Setpoint Temperature_No Tolerance (°C)',\n",
    "        'Adaptive Heating Setpoint Temperature_No Tolerance (°C)',\n",
    "        'Building_Total_Zone Operative Temperature (°C) (mean)',\n",
    "        'BLOCK1:ZONE2_ASHRAE 55 Running mean outdoor temperature (°C)',\n",
    "        'Building_Total_Cooling Energy Demand (kWh/m2) (summed)',\n",
    "        'Building_Total_Heating Energy Demand (kWh/m2) (summed)',\n",
    "        'Building_Total_AFN Zone Infiltration Air Change Rate (ach) (summed)'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7951ffa",
   "metadata": {},
   "source": [
    "And now, let's generate the figure data (a list of lists and dictionaries with all information to be plotted) with `generate_fig_data()` and afterwards, let's plot the figure with `scatter_plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d385ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_hourly.scatter_plot(\n",
    "    vars_to_gather_rows=['EPW'], # variables to gather in rows of subplots\n",
    "    vars_to_gather_cols=['ComfMod', 'HVACmode'],# variables to gather in columns of subplots; all categorical columns which have more than 1 different value across the rows, must be specified in this argument, otherwise you'll get an error.\n",
    "    detailed_cols=['CM_3[HM_1', 'CM_3[HM_2'], # a list of the specific combinations of arguments to be plotted joined by [\n",
    "    data_on_x_axis='BLOCK1:ZONE2_ASHRAE 55 Running mean outdoor temperature (°C)', #column name (string) for the data on x axis\n",
    "    data_on_y_main_axis=[ #list which includes the name of the axis on the first place, and then in the second place, a list which includes the column names you want to plot\n",
    "        [\n",
    "            'Indoor Operative Temperature (°C)',\n",
    "            [\n",
    "                'Adaptive Cooling Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Adaptive Heating Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Building_Total_Zone Operative Temperature (°C) (mean)',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    colorlist_y_main_axis=[\n",
    "        [\n",
    "            'Indoor Operative Temperature (°C)',\n",
    "            [\n",
    "                'b',\n",
    "                'r',\n",
    "                'g',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    rows_renaming_dict={\n",
    "        'Brazil_Chapeco_Present': 'Chapeco Present',\n",
    "        'Brazil_Chapeco_RCP85-2100': 'Chapeco RCP85-2100',\n",
    "        'Brazil_Palmas_Present': 'Palmas Present',\n",
    "        'Brazil_Palmas_RCP85-2100': 'Palmas RCP85-2100',\n",
    "    },\n",
    "    cols_renaming_dict={\n",
    "        'CM_3[HM_1': 'Brazilian model NV',\n",
    "        'CM_3[HM_2': 'Brazilian model MM',\n",
    "    },\n",
    "    supxlabel='Running Mean Outdoor Temperature (°C)', # data label on x axis\n",
    "    figname='Scatterplot_NV_vs_MM',\n",
    "    figsize=6,\n",
    "    ratio_height_to_width=0.33,\n",
    "    confirm_graph=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ad6d2",
   "metadata": {},
   "source": [
    "In this figure, you can see on the left column the simulations with free-running (or naturally ventilated) mode, while on the right, the same simulations using mixed-mode with adaptive setpoint temperatures, which introduce all hourly indoor temperatures within the adaptive thermal comfort limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ac545",
   "metadata": {},
   "source": [
    "Next, let's compare the indoor temperatures of ASHRAE 55, the local Japanese model and the static setpoints for Japan, and in this case, we're also going to plot the hourly energy demand on the secondary axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.scatter_plot(\n",
    "    vars_to_gather_cols=['ComfMod', 'HVACmode'], # variables to gather in rows of subplots\n",
    "    vars_to_gather_rows=['EPW'],# variables to gather in columns of subplots\n",
    "    detailed_cols=['CM_0[HM_2', 'CM_3[HM_1', 'CM_3[HM_2'], #we only want to see those combinations\n",
    "    custom_cols_order=['CM_3[HM_1', 'CM_0[HM_2', 'CM_3[HM_2'],\n",
    "    data_on_x_axis='BLOCK1:ZONE2_ASHRAE 55 Running mean outdoor temperature (°C)', #column name (string) for the data on x axis\n",
    "    data_on_y_main_axis=[ # similarly to above, a list including the name of the secondary y-axis and the column names you want to plot in it\n",
    "        [\n",
    "            'Energy (kWh/m2)',\n",
    "            [\n",
    "                'Building_Total_Cooling Energy Demand (kWh/m2) (summed)',\n",
    "                'Building_Total_Heating Energy Demand (kWh/m2) (summed)',\n",
    "            ]\n",
    "        ],\n",
    "\n",
    "    ],\n",
    "    data_on_y_sec_axis=[ #list which includes the name of the axis on the first place, and then in the second place, a list which includes the column names you want to plot\n",
    "        [\n",
    "            'Air renovation (ach)',\n",
    "            [\n",
    "                'Building_Total_AFN Zone Infiltration Air Change Rate (ach) (summed)'\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            'Operative Temperature (°C)',\n",
    "            [\n",
    "                'Adaptive Cooling Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Adaptive Heating Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Building_Total_Zone Operative Temperature (°C) (mean)',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    colorlist_y_main_axis=[\n",
    "        [\n",
    "            'Energy (kWh/m2)',\n",
    "            [\n",
    "                'cyan',\n",
    "                'orange',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    colorlist_y_sec_axis=[\n",
    "        [\n",
    "            'Air renovation (ach)',\n",
    "            [\n",
    "                'yellow'\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            'Operative Temperature (°C)',\n",
    "            [\n",
    "                'b',\n",
    "                'r',\n",
    "                'g',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "\n",
    "    rows_renaming_dict={\n",
    "        'Brazil_Chapeco_Present': 'Chapeco Present',\n",
    "        'Brazil_Chapeco_RCP85-2100': 'Chapeco RCP85-2100',\n",
    "        'Brazil_Palmas_Present': 'Palmas Present',\n",
    "        'Brazil_Palmas_RCP85-2100': 'Palmas RCP85-2100',\n",
    "    },\n",
    "    cols_renaming_dict={\n",
    "        'CM_3[HM_1': 'Brazilian adaptive NV',        \n",
    "        'CM_0[HM_2': 'Brazilian static MM',\n",
    "        'CM_3[HM_2': 'Brazilian adaptive MM',\n",
    "    },\n",
    "    supxlabel='Running Mean Outdoor Temperature (°C)', # data label on x axis\n",
    "    figname=f'scatterplot_BRA_stat_BRA_adap_BRA_nv',\n",
    "    figsize=6,\n",
    "    ratio_height_to_width=0.33,\n",
    "    confirm_graph=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67927348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_hourly.time_plot(\n",
    "    vars_to_gather_rows=['EPW'], # variables to gather in rows of subplots\n",
    "    vars_to_gather_cols=['ComfMod', 'HVACmode'],# variables to gather in columns of subplots; all categorical columns which have more than 1 different value across the rows, must be specified in this argument, otherwise you'll get an error.\n",
    "    detailed_cols=['CM_3[HM_1', 'CM_3[HM_2'], # a list of the specific combinations of arguments to be plotted joined by [\n",
    "    data_on_y_main_axis=[ #list which includes the name of the axis on the first place, and then in the second place, a list which includes the column names you want to plot\n",
    "        [\n",
    "            'Indoor Operative Temperature (°C)',\n",
    "            [\n",
    "                'Adaptive Cooling Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Adaptive Heating Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Building_Total_Zone Operative Temperature (°C) (mean)',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    colorlist_y_main_axis=[\n",
    "        [\n",
    "            'Indoor Operative Temperature (°C)',\n",
    "            [\n",
    "                'b',\n",
    "                'r',\n",
    "                'g',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    rows_renaming_dict={\n",
    "        'Brazil_Chapeco_Present': 'Chapeco Present',\n",
    "        'Brazil_Chapeco_RCP85-2100': 'Chapeco RCP85-2100',\n",
    "        'Brazil_Palmas_Present': 'Palmas Present',\n",
    "        'Brazil_Palmas_RCP85-2100': 'Palmas RCP85-2100',\n",
    "    },\n",
    "    cols_renaming_dict={\n",
    "        'CM_3[HM_1': 'Brazilian model NV',\n",
    "        'CM_3[HM_2': 'Brazilian model MM',\n",
    "    },\n",
    "    figname='Timeplot_NV_vs_MM',\n",
    "    figsize=6,\n",
    "    ratio_height_to_width=0.33,\n",
    "    confirm_graph=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439256f",
   "metadata": {},
   "source": [
    "### 4.2 Analysing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8ec84",
   "metadata": {},
   "source": [
    "Now, let's see how many comfort hours were considering the NV mode, and afterwards the MM considering ASHRAE 55, as well as the impact on energy demand. Since we want to see the runperiod totals, we will need to make a new instance of Table(), asking for runperiod frequency this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.data.data_postprocessing import Table\n",
    "dataset_runperiod = Table(\n",
    "    #datasets=list #Since we are not specifying any list, it will use all available CSVs in the folder\n",
    "    source_frequency='hourly', # This lets accim know which is the frequency of the input CSVs. Input CSVs with multiple frequencies are also allowed. It can be 'hourly', 'daily', 'monthly' and 'runperiod'. It can also be 'timestep' but might generate errors.\n",
    "    frequency='runperiod', # If 'daily', accim will aggregate the rows in days. It can be 'hourly', 'daily', 'monthly' and 'runperiod'. It can also be 'timestep' but might generate errors.\n",
    "    frequency_agg_func='sum', #this makes the sum or average when aggregating in days, months or runperiod; since the original CSV frequency is in hour, it won't make any aeffect\n",
    "    standard_outputs=True, \n",
    "    level=['building'], # A list containing the strings 'block' and/or 'building'. For instance, if ['block', 'building'], accim will generate new columns to sum up or average in blocks and building level.\n",
    "    level_agg_func=['sum', 'mean'], # A list containing the strings 'sum' and/or 'mean'. For instance, if ['sum', 'mean'], accim will generate the new columns explained in the level argument by summing and averaging.\n",
    "    level_excluded_zones=[],\n",
    "    #match_cities=bool #Only used when EPW file has NOT been previously renamed\n",
    "    #manage_epw_names=bool #Only used when EPW file has NOT been previously renamed\n",
    "    split_epw_names=True, #to split EPW names based on the pattern Country_City_RCPscenario-Year\n",
    ")\n",
    "\n",
    "dataset_runperiod.format_table(\n",
    "    type_of_table='custom',\n",
    "    custom_cols=[\n",
    "        'Building_Total_Comfortable Hours_No Applicability (h) (mean)',\n",
    "        'Building_Total_Total Energy Demand (kWh/m2) (summed)'\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_runperiod.wrangled_table(\n",
    "    reshaping='unstack',\n",
    "    vars_to_gather=['ComfMod', 'HVACmode'],\n",
    "    baseline='CM_3[HM_2',\n",
    "    comparison_mode=['baseline compared to others'],\n",
    "    comparison_cols=[],\n",
    "    rename_dict={\n",
    "        'CM_0[HM_2': 'BRA_Stat_MM',\n",
    "        'CM_3[HM_1': 'BRA_Adap_NV',\n",
    "        'CM_3[HM_2': 'BRA_Adap_MM',\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset_runperiod.wrangled_df_unstacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41cfe5",
   "metadata": {},
   "source": [
    "The table above shows us the comfort hours in NV (BRA_Adap_NV) mode ranges between 7389.50 and 48.92 hours, while the same comfort model in mixed-mode with adaptive setpoints (BRA_Adap_MM) ranges between 8712.00 and 8577.75. Since there is no HVAC system in NV mode, the energy consumption is 0. With adaptive setpoints, the hvac energy demand ranges between 235.10 and 945.55 (kWh/m2·year), while with the static setpoints it ranges between 771.65 and 1171.15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d81f8",
   "metadata": {},
   "source": [
    "Now, let's compare the energy demand from all settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea38904",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_runperiod.format_table(\n",
    "    type_of_table='custom',\n",
    "    custom_cols=[\n",
    "        'Building_Total_Heating Energy Demand (kWh/m2) (summed)',\n",
    "        'Building_Total_Cooling Energy Demand (kWh/m2) (summed)',\n",
    "        'Building_Total_Total Energy Demand (kWh/m2) (summed)',\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_runperiod.wrangled_table(\n",
    "    reshaping='unstack',\n",
    "    vars_to_gather=['ComfMod', 'HVACmode'],\n",
    "    baseline='CM_3[HM_2',\n",
    "    comparison_mode=['baseline compared to others'],\n",
    "    comparison_cols=['relative', 'absolute'],\n",
    "    rename_dict={\n",
    "        'CM_0[HM_2': 'BRA_Stat_MM',\n",
    "        'CM_3[HM_1': 'BRA_Adap_NV',\n",
    "        'CM_3[HM_2': 'BRA_Adap_MM',\n",
    "    },\n",
    "    transpose=True\n",
    ")\n",
    "\n",
    "dataset_runperiod.wrangled_df_unstacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d5b41",
   "metadata": {},
   "source": [
    "For instance, we can see the adaptive setpoints provide reductions in energy demand compared to the satics setpoints ranging between 70 and 19%, depending on the scenarios and climate zones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4501f",
   "metadata": {},
   "source": [
    "Now, we could finally export this table to Excel format for later style edition. Since the reshaping argument we used in the `wrangled_table()` method was 'unstack', the dataframe we are looking for to be exported is `dataset_runperiod.wrangled_df_unstacked`. If we used the 'pivot' argument, the dataframe would have been `dataset_runperiod.wrangled_df_pivoted`. So let's export it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb6604",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dataset_runperiod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_runperiod.wrangled_df_unstacked.to_excel('df_unstacked.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel ('df_unstacked.xlsx')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc70a2",
   "metadata": {},
   "source": [
    "Finally, so that we can run this jupyter notebook again, let's leave everything as it was at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb035b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in original_epws:\n",
    "    shutil.move(f'backup/{i}', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6137656",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_delete = [i for i in listdir() if i not in input_files]\n",
    "print(*files_to_delete, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d79466",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files_to_delete:\n",
    "    remove(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
